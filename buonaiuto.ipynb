{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e602a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the meaningful libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np\n",
    "from random import choices\n",
    "\n",
    "class0 = 0\n",
    "class1 = 1\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "xtrain = train_dataset.data[(train_dataset.targets == class0)|(train_dataset.targets == class1)].data.numpy() #.astype(float)[0:sample] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questa funzione genera un array che corrisponde alla rilevazione di n fotoni \n",
    "#The function in this cell generates an array that corresponds to the detection of n photons\n",
    "#of an image y, after blurring.\n",
    "# n : number of photons\n",
    "# sigma is the blurring parameter\n",
    "# y array 28 x 28\n",
    "\n",
    "def sampling_direct_intensity(y, sigma, n):\n",
    "    ypad = np.pad(y, ((28,28) , (28,28)), mode = 'constant', constant_values=(0, 0))\n",
    "    p_DI = np.zeros(ypad.shape)\n",
    "    for i in range(ypad.shape[0]):\n",
    "        for j in range(ypad.shape[1]):\n",
    "            p_DI[i,j] = np.sum( [ypad[u,v]*np.exp( - ((i - u)**2 + (j - v)**2) / (2*sigma**2) ) \n",
    "                                 for u in range(28,56) for v in range(28,56)] ) / ( 2*np.pi*sigma**2 )\n",
    "    P_norm = p_DI/ np.linalg.norm(p_DI, 1)\n",
    "    \n",
    "    f_DI = np.zeros(ypad.shape)\n",
    "    for i in range(ypad.shape[0]):\n",
    "        for j in range(ypad.shape[1]):\n",
    "            p0 = P_norm[i,j]\n",
    "            f_DI[i,j] = np.random.binomial(n, p0, 1)\n",
    "    f_norm = f_DI/ np.linalg.norm(f_DI, 1)\n",
    "    return f_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9932d1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemple visualization\n",
    "\n",
    "y = xtrain[56]\n",
    "sigma = 1\n",
    "\n",
    "finites1 = sampling_direct_intensity(y, sigma, 1)\n",
    "finites2 = sampling_direct_intensity(y, sigma, 1000)\n",
    "finites3 = sampling_direct_intensity(y, sigma, 5000)\n",
    "finites4 = sampling_direct_intensity(y, sigma, 10000)\n",
    "\n",
    "# Visualize the direct intensity measurement\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "ax[0,0].imshow(finites1, cmap='gray') #, vmin=0, vmax=np.max(y))\n",
    "ax[0,0].set_title('100 fotoni')\n",
    "ax[1,0].imshow(finites2, cmap='gray') #, vmin=0, vmax=np.max(P_norm))\n",
    "ax[1,0].set_title('1000 fotoni')\n",
    "ax[0,1].imshow(finites3, cmap='gray') #, vmin=0, vmax=np.max(y))\n",
    "ax[0,1].set_title('5000 fotoni')\n",
    "ax[1,1].imshow(finites4, cmap='gray') #, vmin=0, vmax=np.max(y))\n",
    "ax[1,1].set_title('10000 fotoni')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ecbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# pre-processing SPADE\n",
    "#\n",
    "# SPADE_preprocessing(y, sigma, n)\n",
    "#\n",
    "# where:\n",
    "#   y is 28x28 array (from MNIST)\n",
    "#   sigma is blurring parameter (float)\n",
    "#   n is number of photons (int)\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "### SPADE pre-processing\n",
    "\n",
    "def SPADE_intensity(y, sigma, f): # sigma >0\n",
    "    med = 14\n",
    "    \n",
    "    # order 0\n",
    "    HG00 = np.sum( [[y[i,j] * np.exp( -( (i-med)**2 + (j-med)**2 ) / (4 * (sigma/f)**2) ) \n",
    "                     for i in range(28)] for j in range(28)] )\n",
    "    # order 1\n",
    "    HG01 = np.sum( [[y[i,j] * ( f*(j-med) )**2 * np.exp( -( (i-med)**2 + (j-med)**2 ) / (4 * (sigma/f)**2)) \n",
    "                     for i in range(28)] for j in range(28)] ) / (4 * sigma**2)\n",
    "    HG10 = np.sum( [[y[i,j] * ( f*(i-med) )**2 * np.exp( -( (i-med)**2 + (j-med)**2 ) / (4 * (sigma/f)**2)) \n",
    "                     for i in range(28)] for j in range(28)] ) / (4 * sigma**2)\n",
    "    # order 2\n",
    "    HG11 = np.sum( [[y[i,j] * ( f*(j-med) )**2 * ( f*(i-med) )**2 * np.exp( -( (i-med)**2 + (j-med)**2 ) / (4 * (sigma/f)**2) ) \n",
    "                     for i in range(28)] for j in range(28)] ) / (16 * sigma**4)\n",
    "    HG02 = np.sum( [[y[i,j] * ( f*(j-med) )**4 * np.exp( -( (i-med)**2 + (j-med)**2 ) / (4 * (sigma/f)**2)) \n",
    "                     for i in range(28)] for j in range(28)] ) / (32 * sigma**4)\n",
    "    HG20 = np.sum( [[y[i,j] * ( f*(i-med) )**4 * np.exp( -( (i-med)**2 + (j-med)**2 ) / (4 * (sigma/f)**2)) \n",
    "                     for i in range(28)] for j in range(28)] ) / (32 * sigma**4)\n",
    "        \n",
    "    norm = HG00 + HG01 + HG10 + HG11 + HG02 + HG20\n",
    "    pHG00 = HG00 / norm\n",
    "    pHG01 = HG01 / norm\n",
    "    pHG10 = HG10 / norm\n",
    "    pHG11 = HG11 / norm\n",
    "    pHG02 = HG02 / norm\n",
    "    pHG20 = HG20 / norm\n",
    "    return pHG00, pHG01, pHG10, pHG11, pHG02, pHG20 \n",
    "\n",
    "# input vec is normalised propability\n",
    "def SPADE_sampling(vec, n):\n",
    "    pvals = vec\n",
    "    #print(pvals)\n",
    "    \n",
    "    if n==0:\n",
    "        return pvals\n",
    "\n",
    "    else:\n",
    "        data = np.random.multinomial(n, pvals, size=1)\n",
    "        data = data/ np.sum(data)\n",
    "        #return [ data[0,1], data[0,2], data[0,3], data[0,4], data[0,5] ]\n",
    "        return [ data[0,0], data[0,1], data[0,2], data[0,3], data[0,4], data[0,5] ]\n",
    "\n",
    "# funzione principale\n",
    "def SPADE_preprocessing(y, sigma, f, n):\n",
    "    vec = SPADE_intensity(y, sigma, f)\n",
    "    return SPADE_sampling(vec, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example spade vector\n",
    "y = x_train[4]\n",
    "vec = SPADE_intensity(y, sigma=15,f=1)\n",
    "data = SPADE_sampling(vec, n=1000)\n",
    "print( SPADE_preprocessing(y, sigma=2, f=1,n=25000) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6875936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now preprocess the entire dataset, fixing sigma and varing the scaling factor f\n",
    "\n",
    "sigma=9.5\n",
    "values_f = [ 1.3 , 1.2 , 1.1 , 1.0 , 0.9 , 0.8 , 0.7 , 0.6 , 0.5 ]\n",
    "N=[100,500,1000,5000,10000]\n",
    "def datas_mult(X,N,sigma):\n",
    "    D=[[[0 for i in range(len(N))] for j in range(len(values_f))] for z in range(len(xtrain))]\n",
    "    for i in range(len(xtrain)):\n",
    "        for j in range(len(N)):\n",
    "            for z in range(len(values_f)):\n",
    "                D[i][z][j]=np.array(SPADE_preprocessing(xtrain[i], sigma=sigma,f=values_f[z],n=N[j]))\n",
    "    return D\n",
    "pre_data=np.array(datas_mult(xtrain,N,sigma))\n",
    "#and save the results\n",
    "np.save(\"preproc_f.npy\",pre_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb3b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Algorithm\n",
    "#hyperparm\n",
    "n_estimators=100 #trees in the RF\n",
    "cv=20 #number of crossvalidation\n",
    "\n",
    "\n",
    "y=train_dataset.targets[(train_dataset.targets == class0)|(train_dataset.targets == class1)].numpy()\n",
    "y=torch.from_numpy(y).to(torch.float64)\n",
    "accuracy,stdev=[[0 for i in range(len(N))] for j in range(len(values_f))],[[0 for i in range(len(N))] for j in range(len(values_f))]\n",
    "\n",
    "for a in range(len(sigma)):\n",
    "    for b in range(len(N)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data[:,a,b,:],y, test_size=0.3,shuffle=True,stratify=y)\n",
    "        rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "        rf_clf.fit(X_train, y_train)\n",
    "        cv_score_rf = cross_val_score(rf_clf, X_test, y_test, cv= 20, scoring = \"accuracy\")\n",
    "        cv_score_rf_m = np.mean(cv_score_rf)\n",
    "        cv_score_rf_std=np.std(cv_score_rf)\n",
    "        accuracy[a][b]=cv_score_rf_m\n",
    "        stdev[a][b]=cv_score_rf_std\n",
    "        \n",
    "        print(cv_score_rf_m,cv_score_rf_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe51513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "sigma_real=9.5/np.array([ 1.3 , 1.2 , 1.1 , 1.0 , 0.9 , 0.8 , 0.7 , 0.6 , 0.5 ])\n",
    "fig = plt.figure()\n",
    "accuracy=np.array(accuracy)\n",
    "stdev=np.array(stdev)\n",
    "plt.errorbar(sigma2, list((accuracy[:,0])), yerr=stdev[:,0], label='$N=100$',marker='o', markersize=8)\n",
    "\n",
    "plt.errorbar(sigma2, list((accuracy[:,1])), yerr=stdev[:,1], label='$N=500$',marker='o', markersize=8)\n",
    "\n",
    "plt.errorbar(sigma2, list((accuracy[:,2])), yerr=stdev[:,2],\n",
    "             label='$N=1000$',marker='o', markersize=8)\n",
    "\n",
    "plt.errorbar(sigma2, list((accuracy[:,3])), yerr=stdev[:,3],\n",
    "             label='$N=5000$',marker='o', markersize=8)\n",
    "\n",
    "\n",
    "#plt.errorbar(sigma, list((accuracy[:,4])), yerr=stdev[:,4],\n",
    " #            label='$N=10000$',marker='o', markersize=8)\n",
    "\n",
    "plt.xticks([8,10,12,14,16,18],fontsize=16)\n",
    "plt.yticks([0.5,0.6,0.7,0.8,0.9,1.0],fontsize=16)\n",
    "plt.xlabel(r\"$\\tilde{\\sigma}$\",fontsize=18)\n",
    "plt.ylabel(\"$Accuracy$\",fontsize=18)\n",
    "plt.legend(loc='lower right',fontsize=13)\n",
    "plt.savefig(\"spade_rf_f.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eqnn-9zWPnI4k-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
