{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# ------------------------------------------------\n",
    "# 1. Load Dataset\n",
    "# ------------------------------------------------\n",
    "train_dir = \"data/EuroSAT/train\"\n",
    "test_dir = \"data/EuroSAT/test\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset  = datasets.ImageFolder(test_dir,  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 2. Autoencoder Definition (16x16 bottleneck)\n",
    "# ------------------------------------------------\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder → compress to 16×16\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  # 64→32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 32→16\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Decoder → reconstruct 64×64\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # 16→32\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),  # 32→64\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        out = self.decoder(z)\n",
    "        return out, z\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3. Train the Autoencoder\n",
    "# ------------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Autoencoder().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 150\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for imgs, _ in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(imgs)\n",
    "        loss = criterion(outputs, imgs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss={total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 4. Save Encoded 16×16 Representations\n",
    "# ------------------------------------------------\n",
    "output_root = Path(\"new_dataset\")\n",
    "(output_root / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "(output_root / \"test\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def save_encoded_split(dataloader, split_name, dataset):\n",
    "    for img_tensor, labels in dataloader:\n",
    "        img_tensor = img_tensor.to(device)\n",
    "        _, encoded = model(img_tensor)   # shape: (B, 32, 16, 16)\n",
    "\n",
    "        # Convert 32-channel bottleneck → single-channel 16×16\n",
    "        encoded_img = encoded.mean(dim=1, keepdim=True)  # (B, 1, 16, 16)\n",
    "\n",
    "        for i in range(encoded_img.size(0)):\n",
    "            class_id = labels[i]\n",
    "            class_name = dataset.classes[class_id]\n",
    "\n",
    "            out_dir = output_root / split_name / class_name\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            filename = f\"{len(os.listdir(out_dir))}.png\"\n",
    "            save_image(encoded_img[i], out_dir / filename)\n",
    "\n",
    "save_encoded_split(train_loader, \"train\", train_dataset)\n",
    "save_encoded_split(test_loader,  \"test\",  test_dataset)\n",
    "\n",
    "print(\"Done! Encoded images saved in new_dataset/\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Get one batch\n",
    "images, _ = next(iter(train_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "# Pass through autoencoder\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    recon, encoded = model(images)\n",
    "\n",
    "# Display sample images\n",
    "for idx in [15, 34, 17, 11, 0]:\n",
    "    original = images[idx].cpu().permute(1, 2, 0)         # (H,W,C)\n",
    "    encoded_img = encoded[idx].mean(dim=0).cpu()          # (16,16)\n",
    "    recon_img = recon[idx].mean(dim=0).cpu()          # (16,16)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,4))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original 64×64\")\n",
    "    plt.imshow(original)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Encoded 16×16\")\n",
    "    plt.imshow(encoded_img, cmap='grey')\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Decoded 64×64\")\n",
    "    plt.imshow(recon_img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eqnn-9zWPnI4k-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
